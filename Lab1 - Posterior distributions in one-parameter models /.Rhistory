likelihoodsKapa <- numeric()
i <- 1
for(k in kapa){
likelihoodsKapa[i] <- vonMiseLikelihood(k, data, mu)
i = i +1
}
posteriorsKapa <- likelihoodsKapa*kapaPrior
plot(kapa, posteriorsKapa, type='l')
source('~/Desktop/TDDE07/Labs/Lab1 - Posterior distributions in one-parameter models /Assign3.R', echo=TRUE)
vonMiseLikelihood <- function(k, y, mu){
return ( prod(exp(k*cos(y-mu))/(2*pi*besselI(k,0)))*dexp(k) )
}
data <-c(-2.44,2.14,2.54,1.83,2.02,2.33,-2.79,2.23, 2.07,2.02)
mu <- 2.39
kapa <- seq(0,10,0.001)
i <- 1
for(k in kapa){
likelihoodsKapa[i] <- vonMiseLikelihood(k, data, mu)
i = i +1
}
plot(x=k,y=likelihoodsKapa)
vonMiseLikelihood <- function(k, y, mu){
return ( prod(exp(k*cos(y-mu))/(2*pi*besselI(k,0)))*dexp(k) )
}
data <-c(-2.44,2.14,2.54,1.83,2.02,2.33,-2.79,2.23, 2.07,2.02)
mu <- 2.39
kapa <- seq(0,10,0.001)
for ( i in 1:length(kapa)){
likelihoodsKapa[i] <- vonMiseLikelihood(k, data, mu)
}
plot(x=k,y=likelihoodsKapa)
vonMiseLikelihood <- function(k, y, mu){
return ( prod(exp(k*cos(y-mu))/(2*pi*besselI(k,0)))*dexp(k) )
}
data <-c(-2.44,2.14,2.54,1.83,2.02,2.33,-2.79,2.23, 2.07,2.02)
mu <- 2.39
kapa <- seq(0,10,0.001)
for ( i in 1:length(kapa)){
likelihoodsKapa[i] <- vonMiseLikelihood(k, data, mu)
}
plot(x=kapa,y=likelihoodsKapa)
vonMiseLikelihood <- function(k, y, mu){
return ( prod(exp(k*cos(y-mu))/(2*pi*besselI(k,0)))*dexp(k) )
}
data <-c(-2.44,2.14,2.54,1.83,2.02,2.33,-2.79,2.23, 2.07,2.02)
mu <- 2.39
kapa <- seq(0,10,0.001)
for ( i in 1:length(kapa)){
likelihoodsKapa[i] <- vonMiseLikelihood(kapa[i], data, mu)
}
plot(x=kapa,y=likelihoodsKapa)
sum(likelihoodsKapa)
vonMiseLikelihood <- function(k, y, mu){
return ( prod(exp(k*cos(y-mu))/(2*pi*besselI(k,0)))*dexp(k) )
}
data <-c(-2.44,2.14,2.54,1.83,2.02,2.33,-2.79,2.23, 2.07,2.02)
mu <- 2.39
kapa <- seq(0,10,0.001)
for ( i in 1:length(kapa)){
likelihoodsKapa[i] <- vonMiseLikelihood(kapa[i], data, mu)
}
plot(x=kapa,y=likelihoodsKapa)
sum(likelihoodsKapa)
vonMiseLikelihood <- function(k, y, mu){
return ( prod(exp(k*cos(y-mu))/(2*pi*besselI(k,0)))*dexp(k) ) #Multiply with dexp(k) to take into account the prior of kapa
}
data <-c(-2.44,2.14,2.54,1.83,2.02,2.33,-2.79,2.23, 2.07,2.02)
mu <- 2.39
kapa <- seq(0,10,0.001)
for ( i in 1:length(kapa)){
likelihoodsKapa[i] <- vonMiseLikelihood(kapa[i], data, mu)
}
likelihoodsKapa <- likelihoodsKapa/sum(likelihoodsKapa)
plot(x=kapa,y=likelihoodsKapa)
sum(likelihoodsKapa)
vonMiseLikelihood <- function(k, y, mu){
return ( prod(exp(k*cos(y-mu))/(2*pi*besselI(k,0)))*dexp(k) ) #Multiply with dexp(k) to take into account the prior of kapa
}
data <-c(-2.44,2.14,2.54,1.83,2.02,2.33,-2.79,2.23, 2.07,2.02)
mu <- 2.39
# Creates a fine grid of Kapa values
kapa <- seq(0,10,0.001)
# Compute the likelihood
for ( i in 1:length(kapa)){
posteriorsKapa[i] <- vonMiseLikelihood(kapa[i], data, mu)
}
posteriorsKapa <- posteriorsKapa/sum(posteriorsKapa)
plot(x=kapa,y=posteriorsKapa)
apprPostMode <- posteriorsKapa[lenght(posteriorsKapa)/2]
apprPostMode <- posteriorsKapa[length(posteriorsKapa)/2]
apprPostMode <- posteriorsKapa[length(posteriorsKapa)/2]
apprPostMode
apprPostMode <- posteriorsKapa[which.max(posteriorsKapa)]
apprPostMode <- posteriorsKapa[which.max(posteriorsKapa)]
apprPostMode
source('~/Desktop/TDDE07/Labs/Lab1 - Posterior distributions in one-parameter models /Assign3.R', echo=TRUE)
apprPostMode <- kapa[which.max(posteriorsKapa)]
apprPostMode
knitr::opts_chunk$set(echo = TRUE)
library(LaplacesDemon)
library(bayestestR)
library(dplyr)
library(plotly)
library(ggplot2)
# Data
n <- 20
s <- 5
f <- n - s
# Prior
alphaPrior <- 2
betaPrior <- 2
# Posterior
alphaPost <- s + alphaPrior
betaPost <- f + betaPrior
# Draws
randomDrawsBeta <- rbeta(20, alphaPost, betaPost)
drawMean <- mean(randomDrawsBeta)
drawSD <- sd(randomDrawsBeta)
# Expected mean and deviation
expectedMean <- alphaPost / (alphaPost + betaPost)
expectedSd <- ((alphaPost * betaPost) / ((alphaPost + betaPost)^2 * (alphaPost + betaPost + 1))) ^0.5
# Prepare vectors to visualize the convergence of the drawn mean and SD towards the true mean and SD. Also a sequence from 1 to 10 000 in intervals of 20
drawMeanVect <- c()
drawSDVect <- c()
drawSeq <- seq(1, 10000, 20)
# Loop to try different number of draws
for (i in drawSeq) {
randomDrawsBeta <- rbeta(i, alphaPost, betaPost)
drawMean <- mean(randomDrawsBeta)
drawSD <- sd(randomDrawsBeta)
drawMeanVect <- append(drawMeanVect, drawMean)
drawSDVect <- append(drawSDVect, drawSD)
}
plot(drawMeanVect,col="blue",main="Sample Mean vs Real",sub="Red: Sampled, Blue: Real",xlab="Number of draws",ylab="Mean")
abline(h=expectedMean,col="red")
plot(drawSDVect,col="blue",main="Sample Sdev vs Real",sub="Red: Sampled, Blue: Real",xlab="Number of draws",ylab="sdev")
abline(h=expectedSd,col="red")
n = 10000
randomDrawsBeta <- rbeta(n, alphaPost, betaPost)
drawAbove03 <- length(which(randomDrawsBeta > 0.3))
postProb <- drawAbove03/n
realProb <- pbeta(0.3, alphaPost, betaPost, lower.tail = FALSE)
randomDrawsBeta <- rbeta(n, alphaPost, betaPost)
logDraws <- log(randomDrawsBeta/(1-randomDrawsBeta))
hist(logDraws, breaks = 50)
density(logDraws)
knitr::include_graphics("logNormDist.png")
knitr::include_graphics("tauSquared.png")
nDraws <- 10000
data <- c(14, 25, 45, 25, 30, 33, 19, 50, 34, 67)
n <- length(data)
mu <- 3.7
tauSquared <- sum((log(data) - mu)^2)/n
# Posterior draws
xDraws <- rchisq(nDraws, n-1)
sigma2Draws <- ((n-1)*tauSquared)/xDraws
# Theoretical inverse chi squared distribution
theoreticalScaledInv <- (((tauSquared*(n/2))^(n/2))/gamma(n/2))*(exp(-n*tauSquared/(seq(0, 2, 0.05)*2)))/((seq(0, 2, 0.05)^(1+(n/2))))
# Plotting the density of the cdf values
hist(sigma2Draws, probability = TRUE, breaks = 100 )
lines(seq(0, 2, 0.05) ,theoreticalScaledInv, col="red")
G <- 2*pnorm(sqrt(sigma2Draws/2), mean = 0, sd = 1) - 1
hist(G, probability = TRUE, breaks = 100, xlim = c(0.1, 0.7))
lines(density(G), col = "red")
# Calculating the credible interval, standard on 90% equal tail
credibleInterval <- p.interval(obj = G, prob = 0.95, HPD = FALSE)
# Adding the credible interval to the graph
hist(G, probability = TRUE, breaks = 100, xlim = c(0.1, 0.7))
lines(density(G), col = "red")
abline(v = credibleInterval, col = "blue", lwd = 2, lty = 2)
# Computing the highest posterior density
HPDInterval <- p.interval(G, prob = 0.95)
# Adding the HPD interval to the graph
abline(v = HPDInterval, col = "green", lwd = 2, lty = 2)
# OBS! Alternative way to compute HPD for G, the way they ask for in the lab
densityG <- density(G)
densityG
sortedDensityG <- sort(densityG$y, decreasing = TRUE)
densityStamp <- 0
count <- 0
while (densityStamp < 0.95) {
count <- count + 1
densityStamp <- sum(sortedDensityG[1:count])/sum(sortedDensityG)
}
densityLimit <- sortedDensityG[count]
densityLimit95 <- which(densityG$y >= densityLimit)
limits <- c(densityG$x[densityLimit95[1]], densityG$x[densityLimit95[length(densityLimit95)]])
HPDInterval
limits
knitr::include_graphics("vonMisesDistr.png")
vonMiseLikelihood <- function(k, y, mu){
#Multiply with dexp(k) to take into account the prior of kapa
return ( prod(exp(k*cos(y-mu))/(2*pi*besselI(k,0)))*dexp(k) )
}
data <-c(-2.44,2.14,2.54,1.83,2.02,2.33,-2.79,2.23, 2.07,2.02)
mu <- 2.39
# Creates a fine grid of Kapa values
kapa <- seq(0,10,0.001)
# Compute the posteriors for each kapa value
for ( i in 1:length(kapa)){
posteriorsKapa[i] <- vonMiseLikelihood(kapa[i], data, mu)
}
posteriorsKapa <- posteriorsKapa/sum(posteriorsKapa)
plot(x=kapa,y=posteriorsKapa)
apprPostMode <- kapa[which.max(posteriorsKapa)]
apprPostMode
knitr::opts_chunk$set(echo = TRUE)
library(LaplacesDemon)
library(bayestestR)
library(dplyr)
library(plotly)
library(ggplot2)
# Data
n <- 20
s <- 5
f <- n - s
# Prior
alphaPrior <- 2
betaPrior <- 2
# Posterior
alphaPost <- s + alphaPrior
betaPost <- f + betaPrior
# Draws
randomDrawsBeta <- rbeta(20, alphaPost, betaPost)
drawMean <- mean(randomDrawsBeta)
drawSD <- sd(randomDrawsBeta)
# Expected mean and deviation
expectedMean <- alphaPost / (alphaPost + betaPost)
expectedSd <- ((alphaPost * betaPost) / ((alphaPost + betaPost)^2 * (alphaPost + betaPost + 1))) ^0.5
# Prepare vectors to visualize the convergence of the drawn mean and SD towards the true mean and SD. Also a sequence from 1 to 10 000 in intervals of 20
drawMeanVect <- c()
drawSDVect <- c()
drawSeq <- seq(1, 10000, 20)
# Loop to try different number of draws
for (i in drawSeq) {
randomDrawsBeta <- rbeta(i, alphaPost, betaPost)
drawMean <- mean(randomDrawsBeta)
drawSD <- sd(randomDrawsBeta)
drawMeanVect <- append(drawMeanVect, drawMean)
drawSDVect <- append(drawSDVect, drawSD)
}
plot(drawMeanVect,col="blue",main="Sample Mean vs Real",sub="Red: Sampled, Blue: Real",xlab="Number of draws",ylab="Mean")
abline(h=expectedMean,col="red")
plot(drawSDVect,col="blue",main="Sample Sdev vs Real",sub="Red: Sampled, Blue: Real",xlab="Number of draws",ylab="sdev")
abline(h=expectedSd,col="red")
n = 10000
randomDrawsBeta <- rbeta(n, alphaPost, betaPost)
drawAbove03 <- length(which(randomDrawsBeta > 0.3))
postProb <- drawAbove03/n
realProb <- pbeta(0.3, alphaPost, betaPost, lower.tail = FALSE)
randomDrawsBeta <- rbeta(n, alphaPost, betaPost)
logDraws <- log(randomDrawsBeta/(1-randomDrawsBeta))
hist(logDraws, breaks = 50)
density(logDraws)
knitr::include_graphics("logNormDist.png")
knitr::include_graphics("tauSquared.png")
nDraws <- 10000
data <- c(14, 25, 45, 25, 30, 33, 19, 50, 34, 67)
n <- length(data)
mu <- 3.7
tauSquared <- sum((log(data) - mu)^2)/n
# Posterior draws
xDraws <- rchisq(nDraws, n-1)
sigma2Draws <- ((n-1)*tauSquared)/xDraws
# Theoretical inverse chi squared distribution
theoreticalScaledInv <- (((tauSquared*(n/2))^(n/2))/gamma(n/2))*(exp(-n*tauSquared/(seq(0, 2, 0.05)*2)))/((seq(0, 2, 0.05)^(1+(n/2))))
# Plotting the density of the cdf values
hist(sigma2Draws, probability = TRUE, breaks = 100 )
lines(seq(0, 2, 0.05) ,theoreticalScaledInv, col="red")
G <- 2*pnorm(sqrt(sigma2Draws/2), mean = 0, sd = 1) - 1
hist(G, probability = TRUE, breaks = 100, xlim = c(0.1, 0.7))
lines(density(G), col = "red")
# Calculating the credible interval, standard on 90% equal tail
credibleInterval <- p.interval(obj = G, prob = 0.95, HPD = FALSE)
# Adding the credible interval to the graph
hist(G, probability = TRUE, breaks = 100, xlim = c(0.1, 0.7))
lines(density(G), col = "red")
abline(v = credibleInterval, col = "blue", lwd = 2, lty = 2)
# Computing the highest posterior density
HPDInterval <- p.interval(G, prob = 0.95)
# Adding the HPD interval to the graph
abline(v = HPDInterval, col = "green", lwd = 2, lty = 2)
# OBS! Alternative way to compute HPD for G, the way they ask for in the lab
densityG <- density(G)
densityG
sortedDensityG <- sort(densityG$y, decreasing = TRUE)
densityStamp <- 0
count <- 0
while (densityStamp < 0.95) {
count <- count + 1
densityStamp <- sum(sortedDensityG[1:count])/sum(sortedDensityG)
}
densityLimit <- sortedDensityG[count]
densityLimit95 <- which(densityG$y >= densityLimit)
limits <- c(densityG$x[densityLimit95[1]], densityG$x[densityLimit95[length(densityLimit95)]])
HPDInterval
limits
knitr::include_graphics("vonMisesDistr.png")
vonMiseLikelihood <- function(k, y, mu){
#Multiply with dexp(k) to take into account the prior of kapa
return ( prod(exp(k*cos(y-mu))/(2*pi*besselI(k,0)))*dexp(k) )
}
data <-c(-2.44,2.14,2.54,1.83,2.02,2.33,-2.79,2.23, 2.07,2.02)
mu <- 2.39
# Creates a fine grid of Kapa values
kapa <- seq(0,10,0.001)
posteriorsKapa <- numeric()
# Compute the posteriors for each kapa value
for ( i in 1:length(kapa)){
posteriorsKapa[i] <- vonMiseLikelihood(kapa[i], data, mu)
}
posteriorsKapa <- posteriorsKapa/sum(posteriorsKapa)
plot(x=kapa,y=posteriorsKapa)
apprPostMode <- kapa[which.max(posteriorsKapa)]
apprPostMode
knitr::opts_chunk$set(echo = TRUE)
library(LaplacesDemon)
library(bayestestR)
library(dplyr)
library(plotly)
library(GGplot2)
knitr::opts_chunk$set(echo = TRUE)
library(LaplacesDemon)
library(bayestestR)
library(dplyr)
library(plotly)
# Data
n <- 20
s <- 5
f <- n - s
# Prior
alphaPrior <- 2
betaPrior <- 2
# Posterior
alphaPost <- s + alphaPrior
betaPost <- f + betaPrior
# Draws
randomDrawsBeta <- rbeta(20, alphaPost, betaPost)
drawMean <- mean(randomDrawsBeta)
drawSD <- sd(randomDrawsBeta)
# Expected mean and deviation
expectedMean <- alphaPost / (alphaPost + betaPost)
expectedSd <- ((alphaPost * betaPost) / ((alphaPost + betaPost)^2 * (alphaPost + betaPost + 1))) ^0.5
# Prepare vectors to visualize the converGence of the drawn mean and SD towards the true mean and SD. Also a sequence from 1 to 10 000 in intervals of 20
drawMeanVect <- c()
drawSDVect <- c()
drawSeq <- seq(1, 10000, 20)
# Loop to try different number of draws
for (i in drawSeq) {
randomDrawsBeta <- rbeta(i, alphaPost, betaPost)
drawMean <- mean(randomDrawsBeta)
drawSD <- sd(randomDrawsBeta)
drawMeanVect <- append(drawMeanVect, drawMean)
drawSDVect <- append(drawSDVect, drawSD)
}
plot(drawMeanVect,col="blue",main="Sample Mean vs Real",sub="Red: Sampled, Blue: Real",xlab="Number of draws",ylab="Mean")
abline(h=expectedMean,col="red")
plot(drawSDVect,col="blue",main="Sample Sdev vs Real",sub="Red: Sampled, Blue: Real",xlab="Number of draws",ylab="sdev")
abline(h=expectedSd,col="red")
n = 10000
randomDrawsBeta <- rbeta(n, alphaPost, betaPost)
drawAbove03 <- lenGth(which(randomDrawsBeta > 0.3))
knitr::opts_chunk$set(echo = TRUE)
library(LaplacesDemon)
library(bayestestR)
library(dplyr)
library(plotly)
# Data
n <- 20
s <- 5
f <- n - s
# Prior
alphaPrior <- 2
betaPrior <- 2
# Posterior
alphaPost <- s + alphaPrior
betaPost <- f + betaPrior
# Draws
randomDrawsBeta <- rbeta(20, alphaPost, betaPost)
drawMean <- mean(randomDrawsBeta)
drawSD <- sd(randomDrawsBeta)
# Expected mean and deviation
expectedMean <- alphaPost / (alphaPost + betaPost)
expectedSd <- ((alphaPost * betaPost) / ((alphaPost + betaPost)^2 * (alphaPost + betaPost + 1))) ^0.5
# Prepare vectors to visualize the converGence of the drawn mean and SD towards the true mean and SD. Also a sequence from 1 to 10 000 in intervals of 20
drawMeanVect <- c()
drawSDVect <- c()
drawSeq <- seq(1, 10000, 20)
# Loop to try different number of draws
for (i in drawSeq) {
randomDrawsBeta <- rbeta(i, alphaPost, betaPost)
drawMean <- mean(randomDrawsBeta)
drawSD <- sd(randomDrawsBeta)
drawMeanVect <- append(drawMeanVect, drawMean)
drawSDVect <- append(drawSDVect, drawSD)
}
plot(drawMeanVect,col="blue",main="Sample Mean vs Real",sub="Red: Sampled, Blue: Real",xlab="Number of draws",ylab="Mean")
abline(h=expectedMean,col="red")
plot(drawSDVect,col="blue",main="Sample Sdev vs Real",sub="Red: Sampled, Blue: Real",xlab="Number of draws",ylab="sdev")
abline(h=expectedSd,col="red")
n = 10000
randomDrawsBeta <- rbeta(n, alphaPost, betaPost)
drawAbove03 <- lenGth(which(randomDrawsBeta > 0.3))
knitr::opts_chunk$set(echo = TRUE)
library(LaplacesDemon)
library(bayestestR)
library(dplyr)
library(plotly)
library(ggplot2)
# Data
n <- 20
s <- 5
f <- n - s
# Prior
alphaPrior <- 2
betaPrior <- 2
# Posterior
alphaPost <- s + alphaPrior
betaPost <- f + betaPrior
# Draws
randomDrawsBeta <- rbeta(20, alphaPost, betaPost)
drawMean <- mean(randomDrawsBeta)
drawSD <- sd(randomDrawsBeta)
# Expected mean and deviation
expectedMean <- alphaPost / (alphaPost + betaPost)
expectedSd <- ((alphaPost * betaPost) / ((alphaPost + betaPost)^2 * (alphaPost + betaPost + 1))) ^0.5
# Prepare vectors to visualize the convergence of the drawn mean and SD towards the true mean and SD. Also a sequence from 1 to 10 000 in intervals of 20
drawMeanVect <- c()
drawSDVect <- c()
drawSeq <- seq(1, 10000, 20)
# Loop to try different number of draws
for (i in drawSeq) {
randomDrawsBeta <- rbeta(i, alphaPost, betaPost)
drawMean <- mean(randomDrawsBeta)
drawSD <- sd(randomDrawsBeta)
drawMeanVect <- append(drawMeanVect, drawMean)
drawSDVect <- append(drawSDVect, drawSD)
}
plot(drawMeanVect,col="blue",main="Sample Mean vs Real",sub="Red: Sampled, Blue: Real",xlab="Number of draws",ylab="Mean")
abline(h=expectedMean,col="red")
plot(drawSDVect,col="blue",main="Sample Sdev vs Real",sub="Red: Sampled, Blue: Real",xlab="Number of draws",ylab="sdev")
abline(h=expectedSd,col="red")
n = 10000
randomDrawsBeta <- rbeta(n, alphaPost, betaPost)
drawAbove03 <- length(which(randomDrawsBeta > 0.3))
postProb <- drawAbove03/n
realProb <- pbeta(0.3, alphaPost, betaPost, lower.tail = FALSE)
randomDrawsBeta <- rbeta(n, alphaPost, betaPost)
logDraws <- log(randomDrawsBeta/(1-randomDrawsBeta))
hist(logDraws, breaks = 50)
density(logDraws)
knitr::include_graphics("logNormDist.png")
knitr::include_graphics("tauSquared.png")
nDraws <- 10000
data <- c(14, 25, 45, 25, 30, 33, 19, 50, 34, 67)
n <- length(data)
mu <- 3.7
tauSquared <- sum((log(data) - mu)^2)/n
# Posterior draws
xDraws <- rchisq(nDraws, n-1)
sigma2Draws <- ((n-1)*tauSquared)/xDraws
# Theoretical inverse chi squared distribution
theoreticalScaledInv <- (((tauSquared*(n/2))^(n/2))/gamma(n/2))*(exp(-n*tauSquared/(seq(0, 2, 0.05)*2)))/((seq(0, 2, 0.05)^(1+(n/2))))
# Plotting the density of the cdf values
hist(sigma2Draws, probability = TRUE, breaks = 100 )
lines(seq(0, 2, 0.05) ,theoreticalScaledInv, col="red")
G <- 2*pnorm(sqrt(sigma2Draws/2), mean = 0, sd = 1) - 1
hist(G, probability = TRUE, breaks = 100, xlim = c(0.1, 0.7))
lines(density(G), col = "red")
# Calculating the credible interval, standard on 90% equal tail
credibleInterval <- p.interval(obj = G, prob = 0.95, HPD = FALSE)
# Adding the credible interval to the graph
hist(G, probability = TRUE, breaks = 100, xlim = c(0.1, 0.7))
lines(density(G), col = "red")
abline(v = credibleInterval, col = "blue", lwd = 2, lty = 2)
# Computing the highest posterior density
HPDInterval <- p.interval(G, prob = 0.95)
# Adding the HPD interval to the graph
abline(v = HPDInterval, col = "green", lwd = 2, lty = 2)
# OBS! Alternative way to compute HPD for G, the way they ask for in the lab
densityG <- density(G)
densityG
sortedDensityG <- sort(densityG$y, decreasing = TRUE)
densityStamp <- 0
count <- 0
while (densityStamp < 0.95) {
count <- count + 1
densityStamp <- sum(sortedDensityG[1:count])/sum(sortedDensityG)
}
densityLimit <- sortedDensityG[count]
densityLimit95 <- which(densityG$y >= densityLimit)
limits <- c(densityG$x[densityLimit95[1]], densityG$x[densityLimit95[length(densityLimit95)]])
HPDInterval
limits
knitr::include_graphics("vonMisesDistr.png")
vonMiseLikelihood <- function(k, y, mu){
#Multiply with dexp(k) to take into account the prior of kapa
return ( prod(exp(k*cos(y-mu))/(2*pi*besselI(k,0)))*dexp(k) )
}
data <-c(-2.44,2.14,2.54,1.83,2.02,2.33,-2.79,2.23, 2.07,2.02)
mu <- 2.39
# Creates a fine grid of Kapa values
kapa <- seq(0,10,0.001)
posteriorsKapa <- numeric()
# Compute the posteriors for each kapa value
for ( i in 1:length(kapa)){
posteriorsKapa[i] <- vonMiseLikelihood(kapa[i], data, mu)
}
posteriorsKapa <- posteriorsKapa/sum(posteriorsKapa)
plot(x=kapa,y=posteriorsKapa)
apprPostMode <- kapa[which.max(posteriorsKapa)]
apprPostMode
